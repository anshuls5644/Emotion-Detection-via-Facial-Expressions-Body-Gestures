# ğŸ­ Emotion Recognition Using Body Gestures and Facial Expressions

A real-time emotion recognition system using **MediaPipe** and **Machine Learning**, capable of detecting and classifying human emotions based on **facial expressions**, **hand gestures**, and **body posture**.

---

## ğŸ“Œ Project Overview

This project combines:
- **MediaPipe Holistic** for extracting body, face, and hand landmarks
- A **trained ML model** for emotion classification
- **OpenCV** for real-time webcam processing and display

---

## ğŸ¯ Goals

- Detect facial and body landmarks in real time
- Extract 2,130 keypoint features per frame
- Predict human emotions like *happy*, *sad*, *angry*, *surprised*, etc.
- Visualize both prediction and facial/pose mesh

---

## ğŸ§  Model Details

The model uses:
- **Pose Landmarks**: 33 points Ã— 4 features = 132
- **Face Landmarks**: 468 points Ã— 4 features = 1,872
- **Left & Right Hand**: 21 Ã— 3 Ã— 2 = 126  
â¡ï¸ **Total**: **2,130 features**

Trained model is stored in `body_language.pkl`.

---

## ğŸ› ï¸ Requirements

Make sure you have **Python 3.7+**. Install dependencies using:

```bash
pip install -r requirements.txt
